{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\preet\\Anaconda3\\envs\\cs231n\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\preet\\Anaconda3\\envs\\cs231n\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.merge import concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import imgaug as ia\n",
    "from tqdm import tqdm\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.utils import Sequence\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os, cv2,copy\n",
    "from phone_pre import BatchGenerator\n",
    "from utils import WeightReader, decode_netout, draw_boxes\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['phone']\n",
    "IMAGE_H, IMAGE_W = 490, 326\n",
    "#IMAGE_H, IMAGE_W = 416, 416\n",
    "GRID_H,  GRID_W  = 5 ,5\n",
    "BOX              = 5\n",
    "CLASS            = len(LABELS)\n",
    "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
    "OBJ_THRESHOLD    = 0.3#0.5\n",
    "NMS_THRESHOLD    = 0.3#0.45\n",
    "\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "BATCH_SIZE       = 2\n",
    "WARM_UP_BATCHES  = 0\n",
    "TRUE_BOX_BUFFER  = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_path = 'yolov2.weights'                      \n",
    "train_image_folder = '/Users/preet/findphone/train_img/'\n",
    "train_annot_folder = '/Users/preet/findphone/train_anno/'\n",
    "valid_image_folder = '/Users/preet/findphone/test_img/'\n",
    "valid_annot_folder = '/Users/preet/findphone/test_anno/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function to implement the orgnization layer (thanks to github.com/allanzelener/YAD2K)\n",
    "def space_to_depth_x2(x):\n",
    "    return tf.space_to_depth(x, block_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1, 3, 4)(?, 1, 3, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_image = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
    "true_boxes  = Input(shape=(1, TRUE_BOX_BUFFER,4 ))\n",
    "print(np.shape(true_boxes))\n",
    "\n",
    "# Layer 1\n",
    "x = Conv2D(32, (3,3), strides=(3,2), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "x = BatchNormalization(name='norm_1')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 2\n",
    "x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_2')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 3\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_3')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 4\n",
    "x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_4')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 5\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_5')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 6\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_6')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 7\n",
    "x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_7')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 8\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_8')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 9\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_9')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 10\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_10')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 11\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_11')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 12\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_12')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 13\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_13')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "skip_connection = x\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 14\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_14')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 15\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_15')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 16\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_16')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 17\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_17')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 18\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_18')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 19\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_19')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 20\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_20')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 21\n",
    "skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
    "skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
    "\n",
    "x = concatenate([skip_connection, x])\n",
    "\n",
    "# Layer 22\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_22')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 23\n",
    "x = Conv2D((2+ CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
    "output = Reshape((GRID_H, GRID_W, 2 + CLASS))(x)\n",
    "\n",
    "# small hack to allow true_boxes to be registered when Keras build the model \n",
    "# for more information: https://github.com/fchollet/keras/issues/2790\n",
    "output = Lambda(lambda args:args[0])([output])\n",
    "\n",
    "model = Model([input_image], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "\n",
      "====================================================================================================================================================================================================\n",
      "\n",
      "input_1 (InputLayer)            (None, 490, 326, 3)  0                                            input_1 (InputLayer)            (None, 490, 326, 3)  0                                            \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "conv_1 (Conv2D)                 (None, 164, 163, 32) 864         input_1[0][0]                    conv_1 (Conv2D)                 (None, 164, 163, 32) 864         input_1[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "norm_1 (BatchNormalization)     (None, 164, 163, 32) 128         conv_1[0][0]                     norm_1 (BatchNormalization)     (None, 164, 163, 32) 128         conv_1[0][0]                     \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 164, 163, 32) 0           norm_1[0][0]                     leaky_re_lu_1 (LeakyReLU)       (None, 164, 163, 32) 0           norm_1[0][0]                     \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 82, 81, 32)   0           leaky_re_lu_1[0][0]              max_pooling2d_1 (MaxPooling2D)  (None, 82, 81, 32)   0           leaky_re_lu_1[0][0]              \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "conv_2 (Conv2D)                 (None, 82, 81, 64)   18432       max_pooling2d_1[0][0]            conv_2 (Conv2D)                 (None, 82, 81, 64)   18432       max_pooling2d_1[0][0]            \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "norm_2 (BatchNormalization)     (None, 82, 81, 64)   256         conv_2[0][0]                     norm_2 (BatchNormalization)     (None, 82, 81, 64)   256         conv_2[0][0]                     \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 82, 81, 64)   0           norm_2[0][0]                     leaky_re_lu_2 (LeakyReLU)       (None, 82, 81, 64)   0           norm_2[0][0]                     \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 41, 40, 64)   0           leaky_re_lu_2[0][0]              max_pooling2d_2 (MaxPooling2D)  (None, 41, 40, 64)   0           leaky_re_lu_2[0][0]              \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "conv_3 (Conv2D)                 (None, 41, 40, 128)  73728       max_pooling2d_2[0][0]            conv_3 (Conv2D)                 (None, 41, 40, 128)  73728       max_pooling2d_2[0][0]            \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "norm_3 (BatchNormalization)     (None, 41, 40, 128)  512         conv_3[0][0]                     norm_3 (BatchNormalization)     (None, 41, 40, 128)  512         conv_3[0][0]                     \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 41, 40, 128)  0           norm_3[0][0]                     leaky_re_lu_3 (LeakyReLU)       (None, 41, 40, 128)  0           norm_3[0][0]                     \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "conv_4 (Conv2D)                 (None, 41, 40, 64)   8192        leaky_re_lu_3[0][0]              conv_4 (Conv2D)                 (None, 41, 40, 64)   8192        leaky_re_lu_3[0][0]              \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "norm_4 (BatchNormalization)     (None, 41, 40, 64)   256         conv_4[0][0]                     norm_4 (BatchNormalization)     (None, 41, 40, 64)   256         conv_4[0][0]                     \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 41, 40, 64)   0           norm_4[0][0]                     leaky_re_lu_4 (LeakyReLU)       (None, 41, 40, 64)   0           norm_4[0][0]                     \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "conv_5 (Conv2D)                 (None, 41, 40, 128)  73728       leaky_re_lu_4[0][0]              conv_5 (Conv2D)                 (None, 41, 40, 128)  73728       leaky_re_lu_4[0][0]              \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "norm_5 (BatchNormalization)     (None, 41, 40, 128)  512         conv_5[0][0]                     norm_5 (BatchNormalization)     (None, 41, 40, 128)  512         conv_5[0][0]                     \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 41, 40, 128)  0           norm_5[0][0]                     \n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 41, 40, 128)  0           norm_5[0][0]                     __________________________________________________________________________________________________\n",
      "\n",
      "__________________________________________________________________________________________________max_pooling2d_3 (MaxPooling2D)  (None, 20, 20, 128)  0           leaky_re_lu_5[0][0]              \n",
      "\n",
      "__________________________________________________________________________________________________max_pooling2d_3 (MaxPooling2D)  (None, 20, 20, 128)  0           leaky_re_lu_5[0][0]              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_6 (Conv2D)                 (None, 20, 20, 256)  294912      max_pooling2d_3[0][0]            __________________________________________________________________________________________________\n",
      "\n",
      "__________________________________________________________________________________________________conv_6 (Conv2D)                 (None, 20, 20, 256)  294912      max_pooling2d_3[0][0]            \n",
      "\n",
      "norm_6 (BatchNormalization)     (None, 20, 20, 256)  1024        conv_6[0][0]                     __________________________________________________________________________________________________\n",
      "\n",
      "__________________________________________________________________________________________________norm_6 (BatchNormalization)     (None, 20, 20, 256)  1024        conv_6[0][0]                     \n",
      "\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 20, 20, 256)  0           norm_6[0][0]                     __________________________________________________________________________________________________\n",
      "\n",
      "__________________________________________________________________________________________________leaky_re_lu_6 (LeakyReLU)       (None, 20, 20, 256)  0           norm_6[0][0]                     \n",
      "\n",
      "conv_7 (Conv2D)                 (None, 20, 20, 128)  32768       leaky_re_lu_6[0][0]              __________________________________________________________________________________________________\n",
      "\n",
      "__________________________________________________________________________________________________conv_7 (Conv2D)                 (None, 20, 20, 128)  32768       leaky_re_lu_6[0][0]              \n",
      "\n",
      "norm_7 (BatchNormalization)     (None, 20, 20, 128)  512         conv_7[0][0]                     __________________________________________________________________________________________________\n",
      "\n",
      "__________________________________________________________________________________________________norm_7 (BatchNormalization)     (None, 20, 20, 128)  512         conv_7[0][0]                     \n",
      "\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 20, 20, 128)  0           norm_7[0][0]                     __________________________________________________________________________________________________\n",
      "\n",
      "__________________________________________________________________________________________________leaky_re_lu_7 (LeakyReLU)       (None, 20, 20, 128)  0           norm_7[0][0]                     \n",
      "\n",
      "conv_8 (Conv2D)                 (None, 20, 20, 256)  294912      leaky_re_lu_7[0][0]              __________________________________________________________________________________________________\n",
      "\n",
      "__________________________________________________________________________________________________conv_8 (Conv2D)                 (None, 20, 20, 256)  294912      leaky_re_lu_7[0][0]              \n",
      "\n",
      "norm_8 (BatchNormalization)     (None, 20, 20, 256)  1024        conv_8[0][0]                     __________________________________________________________________________________________________\n",
      "\n",
      "__________________________________________________________________________________________________norm_8 (BatchNormalization)     (None, 20, 20, 256)  1024        conv_8[0][0]                     \n",
      "\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 20, 20, 256)  0           norm_8[0][0]                     __________________________________________________________________________________________________\n",
      "\n",
      "__________________________________________________________________________________________________leaky_re_lu_8 (LeakyReLU)       (None, 20, 20, 256)  0           norm_8[0][0]                     \n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 10, 256)  0           leaky_re_lu_8[0][0]              \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 10, 256)  0           leaky_re_lu_8[0][0]              conv_9 (Conv2D)                 (None, 10, 10, 512)  1179648     max_pooling2d_4[0][0]            \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "conv_9 (Conv2D)                 (None, 10, 10, 512)  1179648     max_pooling2d_4[0][0]            norm_9 (BatchNormalization)     (None, 10, 10, 512)  2048        conv_9[0][0]                     \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "norm_9 (BatchNormalization)     (None, 10, 10, 512)  2048        conv_9[0][0]                     leaky_re_lu_9 (LeakyReLU)       (None, 10, 10, 512)  0           norm_9[0][0]                     \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 10, 10, 512)  0           norm_9[0][0]                     conv_10 (Conv2D)                (None, 10, 10, 256)  131072      leaky_re_lu_9[0][0]              \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "conv_10 (Conv2D)                (None, 10, 10, 256)  131072      leaky_re_lu_9[0][0]              norm_10 (BatchNormalization)    (None, 10, 10, 256)  1024        conv_10[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "norm_10 (BatchNormalization)    (None, 10, 10, 256)  1024        conv_10[0][0]                    leaky_re_lu_10 (LeakyReLU)      (None, 10, 10, 256)  0           norm_10[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 10, 10, 256)  0           norm_10[0][0]                    conv_11 (Conv2D)                (None, 10, 10, 512)  1179648     leaky_re_lu_10[0][0]             \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "conv_11 (Conv2D)                (None, 10, 10, 512)  1179648     leaky_re_lu_10[0][0]             norm_11 (BatchNormalization)    (None, 10, 10, 512)  2048        conv_11[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 10, 10, 512)  0           norm_11[0][0]                    norm_11 (BatchNormalization)    (None, 10, 10, 512)  2048        conv_11[0][0]                    \n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________conv_12 (Conv2D)                (None, 10, 10, 256)  131072      leaky_re_lu_11[0][0]             \n",
      "\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 10, 10, 512)  0           norm_11[0][0]                    __________________________________________________________________________________________________\n",
      "\n",
      "__________________________________________________________________________________________________norm_12 (BatchNormalization)    (None, 10, 10, 256)  1024        conv_12[0][0]                    \n",
      "\n",
      "conv_12 (Conv2D)                (None, 10, 10, 256)  131072      leaky_re_lu_11[0][0]             __________________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaky_re_lu_12 (LeakyReLU)      (None, 10, 10, 256)  0           norm_12[0][0]                    __________________________________________________________________________________________________\n",
      "\n",
      "__________________________________________________________________________________________________norm_12 (BatchNormalization)    (None, 10, 10, 256)  1024        conv_12[0][0]                    \n",
      "\n",
      "conv_13 (Conv2D)                (None, 10, 10, 512)  1179648     leaky_re_lu_12[0][0]             __________________________________________________________________________________________________\n",
      "\n",
      "__________________________________________________________________________________________________leaky_re_lu_12 (LeakyReLU)      (None, 10, 10, 256)  0           norm_12[0][0]                    \n",
      "\n",
      "norm_13 (BatchNormalization)    (None, 10, 10, 512)  2048        conv_13[0][0]                    __________________________________________________________________________________________________\n",
      "\n",
      "__________________________________________________________________________________________________conv_13 (Conv2D)                (None, 10, 10, 512)  1179648     leaky_re_lu_12[0][0]             \n",
      "\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 10, 10, 512)  0           norm_13[0][0]                    \n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "norm_13 (BatchNormalization)    (None, 10, 10, 512)  2048        conv_13[0][0]                    max_pooling2d_5 (MaxPooling2D)  (None, 5, 5, 512)    0           leaky_re_lu_13[0][0]             \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 10, 10, 512)  0           norm_13[0][0]                    conv_14 (Conv2D)                (None, 5, 5, 1024)   4718592     max_pooling2d_5[0][0]            \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 5, 5, 512)    0           leaky_re_lu_13[0][0]             norm_14 (BatchNormalization)    (None, 5, 5, 1024)   4096        conv_14[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "conv_14 (Conv2D)                (None, 5, 5, 1024)   4718592     max_pooling2d_5[0][0]            leaky_re_lu_14 (LeakyReLU)      (None, 5, 5, 1024)   0           norm_14[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "norm_14 (BatchNormalization)    (None, 5, 5, 1024)   4096        conv_14[0][0]                    conv_15 (Conv2D)                (None, 5, 5, 512)    524288      leaky_re_lu_14[0][0]             \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 5, 5, 1024)   0           norm_14[0][0]                    norm_15 (BatchNormalization)    (None, 5, 5, 512)    2048        conv_15[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "conv_15 (Conv2D)                (None, 5, 5, 512)    524288      leaky_re_lu_14[0][0]             leaky_re_lu_15 (LeakyReLU)      (None, 5, 5, 512)    0           norm_15[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "norm_15 (BatchNormalization)    (None, 5, 5, 512)    2048        conv_15[0][0]                    conv_16 (Conv2D)                (None, 5, 5, 1024)   4718592     leaky_re_lu_15[0][0]             \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 5, 5, 512)    0           norm_15[0][0]                    norm_16 (BatchNormalization)    (None, 5, 5, 1024)   4096        conv_16[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 5, 5, 1024)   0           norm_16[0][0]                    conv_16 (Conv2D)                (None, 5, 5, 1024)   4718592     leaky_re_lu_15[0][0]             \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "norm_16 (BatchNormalization)    (None, 5, 5, 1024)   4096        conv_16[0][0]                    conv_17 (Conv2D)                (None, 5, 5, 512)    524288      leaky_re_lu_16[0][0]             \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 5, 5, 1024)   0           norm_16[0][0]                    norm_17 (BatchNormalization)    (None, 5, 5, 512)    2048        conv_17[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "conv_17 (Conv2D)                (None, 5, 5, 512)    524288      leaky_re_lu_16[0][0]             leaky_re_lu_17 (LeakyReLU)      (None, 5, 5, 512)    0           norm_17[0][0]                    \n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________norm_17 (BatchNormalization)    (None, 5, 5, 512)    2048        conv_17[0][0]                    \n",
      "\n",
      "conv_18 (Conv2D)                (None, 5, 5, 1024)   4718592     leaky_re_lu_17[0][0]             __________________________________________________________________________________________________\n",
      "\n",
      "__________________________________________________________________________________________________leaky_re_lu_17 (LeakyReLU)      (None, 5, 5, 512)    0           norm_17[0][0]                    \n",
      "norm_18 (BatchNormalization)    (None, 5, 5, 1024)   4096        conv_18[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "conv_18 (Conv2D)                (None, 5, 5, 1024)   4718592     leaky_re_lu_17[0][0]             leaky_re_lu_18 (LeakyReLU)      (None, 5, 5, 1024)   0           norm_18[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "norm_18 (BatchNormalization)    (None, 5, 5, 1024)   4096        conv_18[0][0]                    conv_19 (Conv2D)                (None, 5, 5, 1024)   9437184     leaky_re_lu_18[0][0]             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 5, 5, 1024)   0           norm_18[0][0]                    norm_19 (BatchNormalization)    (None, 5, 5, 1024)   4096        conv_19[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "conv_19 (Conv2D)                (None, 5, 5, 1024)   9437184     leaky_re_lu_18[0][0]             conv_21 (Conv2D)                (None, 10, 10, 64)   32768       leaky_re_lu_13[0][0]             \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "norm_19 (BatchNormalization)    (None, 5, 5, 1024)   4096        conv_19[0][0]                    leaky_re_lu_19 (LeakyReLU)      (None, 5, 5, 1024)   0           norm_19[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "conv_21 (Conv2D)                (None, 10, 10, 64)   32768       leaky_re_lu_13[0][0]             norm_21 (BatchNormalization)    (None, 10, 10, 64)   256         conv_21[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 5, 5, 1024)   0           norm_19[0][0]                    conv_20 (Conv2D)                (None, 5, 5, 1024)   9437184     leaky_re_lu_19[0][0]             \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "norm_21 (BatchNormalization)    (None, 10, 10, 64)   256         conv_21[0][0]                    leaky_re_lu_21 (LeakyReLU)      (None, 10, 10, 64)   0           norm_21[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "conv_20 (Conv2D)                (None, 5, 5, 1024)   9437184     leaky_re_lu_19[0][0]             norm_20 (BatchNormalization)    (None, 5, 5, 1024)   4096        conv_20[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 10, 10, 64)   0           norm_21[0][0]                    lambda_1 (Lambda)               (None, 5, 5, 256)    0           leaky_re_lu_21[0][0]             \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "norm_20 (BatchNormalization)    (None, 5, 5, 1024)   4096        conv_20[0][0]                    leaky_re_lu_20 (LeakyReLU)      (None, 5, 5, 1024)   0           norm_20[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "lambda_1 (Lambda)               (None, 5, 5, 256)    0           leaky_re_lu_21[0][0]             concatenate_1 (Concatenate)     (None, 5, 5, 1280)   0           lambda_1[0][0]                   \n",
      "\n",
      "__________________________________________________________________________________________________                                                                 leaky_re_lu_20[0][0]             \n",
      "\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 5, 5, 1024)   0           norm_20[0][0]                    __________________________________________________________________________________________________\n",
      "\n",
      "__________________________________________________________________________________________________conv_22 (Conv2D)                (None, 5, 5, 1024)   11796480    concatenate_1[0][0]              \n",
      "\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 1280)   0           lambda_1[0][0]                   __________________________________________________________________________________________________\n",
      "\n",
      "                                                                 leaky_re_lu_20[0][0]             norm_22 (BatchNormalization)    (None, 5, 5, 1024)   4096        conv_22[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "conv_22 (Conv2D)                (None, 5, 5, 1024)   11796480    concatenate_1[0][0]              leaky_re_lu_22 (LeakyReLU)      (None, 5, 5, 1024)   0           norm_22[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "norm_22 (BatchNormalization)    (None, 5, 5, 1024)   4096        conv_22[0][0]                    conv_23 (Conv2D)                (None, 5, 5, 3)      3075        leaky_re_lu_22[0][0]             \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 5, 5, 1024)   0           norm_22[0][0]                    reshape_1 (Reshape)             (None, 5, 5, 3)      0           conv_23[0][0]                    \n",
      "\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "conv_23 (Conv2D)                (None, 5, 5, 3)      3075        leaky_re_lu_22[0][0]             lambda_2 (Lambda)               (5, 5, 3)            0           reshape_1[0][0]                  \n",
      "\n",
      "__________________________________________________________________________________________________==================================================================================================\n",
      "\n",
      "reshape_1 (Reshape)             (None, 5, 5, 3)      0           conv_23[0][0]                    Total params: 50,551,011\n",
      "\n",
      "__________________________________________________________________________________________________Trainable params: 50,530,339\n",
      "\n",
      "lambda_2 (Lambda)               (5, 5, 3)            0           reshape_1[0][0]                  Non-trainable params: 20,672\n",
      "\n",
      "==================================================================================================__________________________________________________________________________________________________\n",
      "\n",
      "Total params: 50,551,011\n",
      "Trainable params: 50,530,339\n",
      "Non-trainable params: 20,672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_reader  = WeightReader(wt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_reader.reset()\n",
    "nb_conv = 23\n",
    "\n",
    "for i in range(1, nb_conv+1):\n",
    "    conv_layer = model.get_layer('conv_' + str(i))\n",
    "    \n",
    "    if i < nb_conv:\n",
    "        norm_layer = model.get_layer('norm_' + str(i))\n",
    "        \n",
    "        size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "\n",
    "        beta  = weight_reader.read_bytes(size)\n",
    "        gamma = weight_reader.read_bytes(size)\n",
    "        mean  = weight_reader.read_bytes(size)\n",
    "        var   = weight_reader.read_bytes(size)\n",
    "\n",
    "        weights = norm_layer.set_weights([gamma, beta, mean, var])       \n",
    "        \n",
    "    if len(conv_layer.get_weights()) > 1:\n",
    "        bias   = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "        kernel = kernel.transpose([2,3,1,0])\n",
    "        conv_layer.set_weights([kernel, bias])\n",
    "    else:\n",
    "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "        kernel = kernel.transpose([2,3,1,0])\n",
    "        conv_layer.set_weights([kernel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer   = model.layers[-3] # the last convolutional layer\n",
    "weights = layer.get_weights()\n",
    "\n",
    "new_kernel = np.random.normal(size=weights[0].shape)/(GRID_H*GRID_W)\n",
    "new_bias   = np.random.normal(size=weights[1].shape)/(GRID_H*GRID_W)\n",
    "\n",
    "layer.set_weights([new_kernel, new_bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    mask_shape = tf.shape(y_true)[:2]\n",
    "    \n",
    "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1)))\n",
    "    cell_y = tf.transpose(cell_x, (0,2,1,3))\n",
    "\n",
    "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, 1])\n",
    "    \n",
    "    coord_mask = tf.zeros(mask_shape)\n",
    "    class_mask = tf.zeros(mask_shape)\n",
    "    \n",
    "    seen = tf.Variable(0.)\n",
    "    total_recall = tf.Variable(0.)\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust prediction\n",
    "    \"\"\"\n",
    "\n",
    "    ### adjust x and y      \n",
    "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
    "    \n",
    "    ### adjust class probabilities\n",
    "    pred_box_class = y_pred[..., 2:]\n",
    "    print(np.shape(y_pred))\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust ground truth\n",
    "    \"\"\"\n",
    "    # adjust x and y\n",
    "    true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
    "\n",
    "    # adjust class probabilities\n",
    "    true_box_class = tf.argmax(y_true[..., 2:], -1)\n",
    "    print(np.shape(y_true))\n",
    "    \n",
    "    \"\"\"\n",
    "    Determine the masks\n",
    "    \"\"\"\n",
    "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
    "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n",
    "    \n",
    "    \n",
    "    ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
    "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
    "    true_xy = true_boxes[..., 0:2]\n",
    "    \n",
    "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
    "    \n",
    "    ### class mask: simply the position of the ground truth boxes (the predictors)\n",
    "    class_mask = y_true[..., 4] * tf.gather(CLASS_WEIGHTS, true_box_class) * CLASS_SCALE       \n",
    "    \n",
    "    \"\"\"\n",
    "    Warm-up training\n",
    "    \"\"\"\n",
    "    no_boxes_mask = tf.to_float(coord_mask < COORD_SCALE/2.)\n",
    "    seen = tf.assign_add(seen, 1.)\n",
    "    \n",
    "    true_box_xy, coord_mask = tf.cond(tf.less(seen, WARM_UP_BATCHES), \n",
    "                          lambda: [true_box_xy + (0.5 + cell_grid),\n",
    "                                  tf.ones_like(coord_mask)],\n",
    "                          lambda: [true_box_xy,\n",
    "                                  coord_mask])\n",
    "    \n",
    "    \"\"\"\n",
    "    Finalize the loss\n",
    "    \"\"\"\n",
    "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
    "\n",
    "    nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
    "    \n",
    "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
    "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
    "    \n",
    "    loss = loss_xy + loss_class\n",
    "\n",
    "    loss = tf.Print(loss, [tf.zeros((1))], message='Dummy Line \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_xy], message='Loss XY \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_class], message='Loss Class \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss], message='Total Loss \\t', summarize=1000)\n",
    "\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_config = {\n",
    "    'IMAGE_H'         : IMAGE_H, \n",
    "    'IMAGE_W'         : IMAGE_W,\n",
    "    'GRID_H'          : GRID_H,  \n",
    "    'GRID_W'          : GRID_W,\n",
    "    'LABELS'          : LABELS,\n",
    "    'CLASS'           : len(LABELS),\n",
    "    'BATCH_SIZE'      : BATCH_SIZE,\n",
    "    'TRUE_BOX_BUFFER' : 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return image / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'labels.txt'\n",
    "f=open(file,\"r\")\n",
    "lines = [line.rstrip('\\n') for line in open(file)]\n",
    "all_imgs = []\n",
    "seen_labels = {}\n",
    "\n",
    "j=1\n",
    "for x in lines:\n",
    "    img={}\n",
    "    img['name'] = (x.split(' ')[0])\n",
    "    img['x'] = (x.split(' ')[1])\n",
    "    img['y'] = (x.split(' ')[2])\n",
    "    img['filename']= train_image_folder+(x.split(' ')[0])\n",
    "    all_imgs.append(img)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phone_pre import BatchGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = (all_imgs[0:99])\n",
    "train_batch = BatchGenerator(train_imgs, generator_config, norm=normalize,jitter=False)\n",
    "\n",
    "\n",
    "valid_imgs = (all_imgs[100:129])\n",
    "valid_batch = BatchGenerator(valid_imgs, generator_config, norm=normalize, jitter=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', \n",
    "                           min_delta=0.001, \n",
    "                           patience=3, \n",
    "                           mode='min', \n",
    "                           verbose=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint('phone_weights.h5', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min', \n",
    "                             period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 5, 5, 3)(?, 5, 5, 3)\n",
      "\n",
      "(?, ?, ?)(?, ?, ?)\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Rank mismatch: Rank of labels (received 2) should equal rank of logits minus 1 (received 4).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-6552129ded96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#optimizer = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m model.fit_generator(generator        = train_batch, \n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cs231n\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    828\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[1;32m--> 830\u001b[1;33m                                                 sample_weight, mask)\n\u001b[0m\u001b[0;32m    831\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cs231n\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mweighted\u001b[1;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[0;32m    427\u001b[0m         \"\"\"\n\u001b[0;32m    428\u001b[0m         \u001b[1;31m# score_array has ndim >= 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m         \u001b[0mscore_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-e5058c81c21f>\u001b[0m in \u001b[0;36mcustom_loss\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mloss_xy\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_box_xy\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpred_box_xy\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;33m*\u001b[0m \u001b[0mcoord_mask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnb_coord_box\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mloss_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_softmax_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrue_box_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpred_box_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[0mloss_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_class\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mclass_mask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnb_class_box\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cs231n\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[1;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[0;32m   2038\u001b[0m       raise ValueError(\"Rank mismatch: Rank of labels (received %s) should \"\n\u001b[0;32m   2039\u001b[0m                        \u001b[1;34m\"equal rank of logits minus 1 (received %s).\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2040\u001b[1;33m                        (labels_static_shape.ndims, logits.get_shape().ndims))\n\u001b[0m\u001b[0;32m   2041\u001b[0m     if (static_shapes_fully_defined and\n\u001b[0;32m   2042\u001b[0m         labels_static_shape != logits.get_shape()[:-1]):\n",
      "\u001b[1;31mValueError\u001b[0m: Rank mismatch: Rank of labels (received 2) should equal rank of logits minus 1 (received 4)."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Rank mismatch: Rank of labels (received 2) should equal rank of logits minus 1 (received 4).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-6552129ded96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#optimizer = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m model.fit_generator(generator        = train_batch, \n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cs231n\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    828\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[1;32m--> 830\u001b[1;33m                                                 sample_weight, mask)\n\u001b[0m\u001b[0;32m    831\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cs231n\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mweighted\u001b[1;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[0;32m    427\u001b[0m         \"\"\"\n\u001b[0;32m    428\u001b[0m         \u001b[1;31m# score_array has ndim >= 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m         \u001b[0mscore_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-e5058c81c21f>\u001b[0m in \u001b[0;36mcustom_loss\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mloss_xy\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_box_xy\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpred_box_xy\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;33m*\u001b[0m \u001b[0mcoord_mask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnb_coord_box\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mloss_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_softmax_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrue_box_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpred_box_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[0mloss_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_class\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mclass_mask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnb_class_box\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cs231n\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[1;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[0;32m   2038\u001b[0m       raise ValueError(\"Rank mismatch: Rank of labels (received %s) should \"\n\u001b[0;32m   2039\u001b[0m                        \u001b[1;34m\"equal rank of logits minus 1 (received %s).\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2040\u001b[1;33m                        (labels_static_shape.ndims, logits.get_shape().ndims))\n\u001b[0m\u001b[0;32m   2041\u001b[0m     if (static_shapes_fully_defined and\n\u001b[0;32m   2042\u001b[0m         labels_static_shape != logits.get_shape()[:-1]):\n",
      "\u001b[1;31mValueError\u001b[0m: Rank mismatch: Rank of labels (received 2) should equal rank of logits minus 1 (received 4)."
     ]
    }
   ],
   "source": [
    "tb_counter  = len([log for log in os.listdir(os.path.expanduser('~/logs/')) if 'phone_' in log]) + 1\n",
    "tensorboard = TensorBoard(log_dir=os.path.expanduser('~/logs/') + 'phone_' + '_' + str(tb_counter), \n",
    "                          histogram_freq=0, \n",
    "                          write_graph=True, \n",
    "                          write_images=False)\n",
    "\n",
    "optimizer = Adam(lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#optimizer = SGD(lr=1e-4, decay=0.0005, momentum=0.9)\n",
    "#optimizer = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss=custom_loss, optimizer=optimizer)\n",
    "\n",
    "model.fit_generator(generator        = train_batch, \n",
    "                    steps_per_epoch  = len(train_batch), \n",
    "                    epochs           = 10, \n",
    "                    verbose          = 1,\n",
    "                    validation_data  = valid_batch,\n",
    "                    validation_steps = len(valid_batch),\n",
    "                    callbacks        = [early_stop, checkpoint, tensorboard], \n",
    "                    max_queue_size   = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
